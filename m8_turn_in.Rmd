---
title: "Milestone 8: To Turn In"
author: "Maria Burzillo"
date: "3/28/2020"
output: 
  pdf_document:
    extra_dependencies: ["rotating"]
bibliography: trounstine_bib.bib
#biblio-style: "apalike"
link_citations: true
header_includes:
  - \usepackage{float}
  - \usepackage{dcolumn}
  - \usepackage{rotating}
  
---

# Abstract

This is an extension of Jessica Trounstine's "Segregation and Inequality in Public Goods" (2016). I was able to replicate the main results of Trounstine's paper in R to suggest that racial segregation contributes to political polarization and decreased spending on public goods. Additionally, I extend the analysis by imputing missing data and rerunning Trounstine's original model as a robustness check. 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
knitr::write_bib(c("knitr", "stringr"), "bib.bib", width = 60)
library(haven)
library(gtable)
library(stargazer)
library(tidyverse)
library(gt)
library(gtsummary)
library(knitr)
library(stargazer)
library(lme4)
library(margins)
library(reprex)
library(plm)
library(devtools)
library(lfe)
library(Statamarkdown)
library(readxl)
library(starpolishr)
library(AER)
library(readxl)
library(naniar)
library(mice)
library(gtsummary)
library(VIM)
```

```{r data_imports, include = FALSE}

# import both datasets

rp <- read_dta("racial_polarization_winners.dta")
fin_seg<- read_dta("fin_seg.dta")

# add row numbers for fin_seg

fin_seg$row_num <- as.integer(rownames(fin_seg))

# import stata geo_id data

regression_ids_edit <- read_excel("regression_ids_edit.xlsx")

nrow(regression_ids_edit %>%
  filter(in_reg == 1))


# find the ones in the stata regression and run it just on those for a sanity check. then try to see why they were included in one but not the other 

```


```{r data_cleaning_rp, include = FALSE}

# create a factor for year for the rp dataset
rp$year.f <- as.factor(rp$year)

# apply the condition that winner == 1 as in the Stata code for the rp regressions

rp_1<- rp %>%
  filter(winner == 1) %>%
  mutate(medincinterp = medincinterp/1000)

```


# Extension 1

One aspect of Trounstine's paper with room for improvement is that there is a large amount of missing data in her datasets upon which she bases her analyses. Using R's mice package (add citation), we can perform multiple imputation. By performing imputation multiple times, this helps account for the uncertainty inherent in the individual imputations. Before performing the multiple imputations, we will first look at the missing data to see if there are any patterns. 

```{r data_prep, include = FALSE}

# select the relevant rows from the rp dataset

rp_impute <- rp %>%
  select("winner", "medincinterp",
             "biggestsplit", "H_citytract_multi_i", "diversityinterp",
             "pctasianpopinterp", "pctblkpopinterp", "pctlatinopopinterp",
             "pctrentersinterp", "pctcollegegradinterp", "biracial", "nonpartisan",
             "primary", "logpop", "year", "south", "midwest", "west", "geo_id2",
             "H_citytract_NHW_i", "whiteideology_fill2") %>%
  filter(winner == 1) %>%
  mutate(medincinterp = medincinterp/1000,
         year.f = as.factor(year))

```

```{r rp_missing_plot, echo = FALSE, warning = FALSE}

# don't show the warning, it's just an irrelevant column missing a name

# plot the missing variables if desired

rp_facet <- rp_impute %>%
   select("medincinterp",
             "biggestsplit", "diversityinterp",
             "pctasianpopinterp", "pctblkpopinterp", "pctlatinopopinterp",
             "pctrentersinterp", "pctcollegegradinterp", "biracial", "nonpartisan",
               "south", "midwest", "west", "whiteideology_fill2", "year")

gg_miss_var(rp_impute, show_pct = TRUE)


```

The above plot reveals that biggestsplit and biracial are the two variables with by far the largest percentage of missing values. Both of these are missing approximately 50% of their observations. Since biggestsplit is the dependent variable in our analysis with this dataset, this is an important fact. 

```{r echo = FALSE}

rp_aggr <- rp_impute %>%
   select("medincinterp",
             "biggestsplit", "diversityinterp",
             "pctasianpopinterp", "pctblkpopinterp", "pctlatinopopinterp",
             "pctrentersinterp", "pctcollegegradinterp", "biracial", "nonpartisan",
               "south", "midwest", "west", "whiteideology_fill2")

aggr_plot <- aggr(rp_aggr, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, cex.axis=.5, gap=1, ylab=c("Histogram of missing data","Pattern"))

# this plot tells us that 42% of the data are not missing anything 
```
To better understand any potential patterns in missing data, we then plotted the pattern of missingness for only those variables missing values. From the plot on the right, we can see that approximately 42% of observations are complete. There seem to be a correspondence between missing a value for biggest split and missing biracial. There also seem to be about 2% of values for wich most of the variables are missing. However, most observations are not missing more than 2-3 values. 

Finding no clear patterns in the missing data, I next performed mutliple imputations (with 10 iterations) on the dataset. A non-stochastic imputation method, Classification and Regression Trees (CART), was used instead of the default because of an error with matrix inversion caused by the data. Before examining the results of Trounstine's model using the imputed data, I first run some diagnostic tests of the imputation results to make sure that everything is running as expected. 

```{r, include = FALSE}
# Perform multiple imputations using the cart method. Because of the time it
# takes to run this function, I turned the results into a dataset to load in
# instead of re-running everytime.

imp_1_rp <- mice(rp_impute, method = "cart", maxit = 10)

# write.csv(complete(imp_1_rp), "imp_1_rp.csv")

# import new data frame with imputed data

#imp_1_rp <- read_csv("imp_1_rp.csv")

# can use the line below to check that there are now no missing values

# gg_miss_var(complete(imp_1_rp), show_pct = TRUE)

```

First, I check the convergence of the algorithm used within mice() for each of the variables. For the most part, the fits intertwine and do not exhibit any trends at later iterations, as desired. There are some issues with the results for some of the variables with very few missing values (such as West and South), which makes sense as we would expect the mean to be less reliable due to the law of large numbers, and convergence is more difficult. Nevertheless, since there are so few of these values in the actual dataset, this is not a major concern.

```{r imp_plot, echo = FALSE}

# ideally, the fits will intertwine and not exhibit any trends at later iterations. This seems to generally be the case. There are some issues with the results for some of the variables with very few missing values, which makes sense as we would expect the mean to be less reliable due to the law of large numbers and thus convergence is more difficult. However, since these are so few values, it is less important about how robust they are. 

plot(imp_1_rp)

```

We can also check the imputed values against the original values using stripplot(). Each column in each subplot represents a separate iteration. The magenta points represent the imputed data. The values of the variable in questions are along the y axis. We expect the spread of the data to be similar if the imputations were done well. If the data were missing completely at random, then the imputed data should have the same distribution as the original data. In particular, we want to be sure that the imputations are within a plausible range of the data. This is the case for all of our imputed variables, and there does not seem to be cause for alarm from these results. 

```{r rp_stripplot, echo = FALSE}

# we can also check the imputed values against the original values using stripplot(). Each column in each subplot represents a separate iteration. The magenta points represent the imputed data. The values of the variable in questions are along the y axis. We expect the spread of the data to be similar if the imputations were done well. If the data were missing completely at random, then the imputed data should have the same distribution as the original data. In particular, we want to be sure that the imputations are within a plausible range of the data. This is the case for all of our imputed variables, and there does not seem to be cause for alarm from these results. 

# this looks good? All reasonable values...

stripplot(imp_1_rp)

stripplot(imp_1_rp, biggestsplit)

```

Finally, we can also look at the density plots for each variable's actual data and for their imputed data from each of the iterations, which are represented in magenta. Overall, the density plots align quite well for the variables with the most missing data, biracial and biggestsplit, and relatively well for most of the other variables with missing data. Again, the fit is less good for variables with fewer missing data points. 

```{r rp_densityplot, echo = FALSE}

densityplot(imp_1_rp)

```

While the imputations are not perfect, there do not seem to be any major problems so far. Thus, we can now proceed with our analysis. We fit each of our ten imputed datasets to Trounstine's 3 models using this data and then pool the results for each. The results are as follows:


```{r rp_imputations, include = FALSE}

# Now that we have imputed the missing data, we can re-run the analyses from the
# original paper to see how and if this changes the analysis. We can use the
# with() function from the mice package to fit each of the imputed datasets to
# the model and then pool the results afterwards.

# regression 1: fit multiple imputed datasets

fit_imp_1_rp <- with(imp_1_rp, lmer(formula = biggestsplit ~ H_citytract_multi_i + diversityinterp + pctasianpopinterp + pctblkpopinterp + pctlatinopopinterp + medincinterp + pctrentersinterp +  pctcollegegradinterp + biracial + nonpartisan + primary + logpop + year.f + south + midwest + west + (1 | geo_id2), REML=FALSE))

# pool and summarize the analyses

pool_imp_1_rp <- pool(fit_imp_1_rp)
imp_1_rp_sum <- summary(pool_imp_1_rp)

## regression 2 Table 1: fit multiple imputed datasets

#formula = biggestsplit ~ H_citytract_NHW_i + diversityinterp + pctasianpopinterp + pctblkpopinterp + pctlatinopopinterp + medincinterp + pctrentersinterp +  pctcollegegradinterp + biracial + nonpartisan + primary + logpop + year.f + south + midwest + west + (1 | geo_id2)

fit_imp_2_rp <- with(imp_1_rp, lmer(biggestsplit ~ H_citytract_NHW_i + diversityinterp + pctasianpopinterp + pctblkpopinterp + pctlatinopopinterp + medincinterp + pctrentersinterp +  pctcollegegradinterp + biracial + nonpartisan + primary + logpop + year.f + south + midwest + west + (1 | geo_id2), REML=FALSE))
                     
# pool and summarize the analyses

pool_imp_2_rp <- pool(fit_imp_2_rp)
imp_2_rp_sum <- summary(pool_imp_2_rp)


## regression 3 Table 1 with new data

#formula = biggestsplit ~ H_citytract_NHW_i + diversityinterp + pctasianpopinterp + pctblkpopinterp + pctlatinopopinterp + medincinterp + pctrentersinterp +  pctcollegegradinterp + biracial + nonpartisan + primary + logpop + whiteideology_fill2 + year.f + south + midwest + west + (1 | geo_id2)

fit_imp_3_rp <- with(imp_1_rp, lmer(biggestsplit ~ H_citytract_NHW_i + diversityinterp + pctasianpopinterp + pctblkpopinterp + pctlatinopopinterp + medincinterp + pctrentersinterp +  pctcollegegradinterp + biracial + nonpartisan + primary + logpop + whiteideology_fill2 + year.f + south + midwest + west + (1 | geo_id2), REML=FALSE))

# pool and summarize the analyses

pool_imp_3_rp <- pool(fit_imp_3_rp)
imp_3_rp_sum <- summary(pool_imp_3_rp)

```


## Extension 1 Racial Polarization Table

```{r results="asis", echo = FALSE, include = FALSE}

# create a stargazer table of the results

#t1_imp <- stargazer(fit_imp_3_rp, 
                    #omit = c("year.f", "south", "midwest", "west"),
#                header = FALSE,
#                title = "\\textbf{Racial Polarization in Segregated Cities}")

```


```{r echo = FALSE, include = FALSE}
  
#gt(imp_1_rp_sum_table) %>%
#  tab_header(title = md("**Extension 1 RP Regression 1**"),
#             subtitle = "")


#gt(imp_1_rp_sum_table)
  
#cols_label(term = md("**Term**"), estimate = md("**Estimate**"), std.error = md("**SD**"), p.value = md("**P Value**")) 


```


## Regression 1

```{r results_printing_rp_impute_regressions_1, echo=FALSE}

# print results of 1st regression

imp_1_rp_sum_table <- as.data.frame(imp_1_rp_sum %>% 
  select(term, estimate, std.error, p.value)) %>%
  head(13)
print(imp_1_rp_sum_table)


stargazer(imp_1_rp_sum_table,
          header = "Racial Divide with Multigroup Segregation Index",
          title = "\\textbf{Racial Polarization in Segregated Cities}")

```

The results of the model with the new dataset are slightly different in comparison to the original results from Trounstine (2016). With the imputed data, we now have a total of `r nrow(complete(rp_impute))` observations in our model as compared to the original model, which had only 91 observations. Interestingly, while the sign of the coefficient on the main variable of interest, the Theil's H segregation index is the same and the standard error has decreased slightly, the result has become statisically insignificant and the 95% confidence interval contains zero. Thus while these results still suggest that segregation may be associated with increased political polarization, they confer a lesser degree of certainty than Trounstine's original analysis. The coefficients for pctblkpopinterp, pctlatinopopinterp, and medincinterp have also switched signs, and all coefficients except indicators for a biracial and primary election are also statistically insignificant, as was the case in the original analysis. In general, the standard error on the coefficients has decreased slightly. 

In the second and third regressions, the results are similar in comparison to the unimputed data to the first. Standard errors have reduced slightly. The main coefficient on segregation index has decreased in magnitude, although in these specifications, it remains statistically significant. The other coefficients except for biracial and primary are insignificant, and the coefficients on percent Asian, Black, and Latino have all switched signs. 

## Regression 2

```{r results_printing_rp_impute_regressions_2, echo=FALSE}

# print results of 2nd regression

imp_2_rp_sum_table <- as.data.frame(imp_2_rp_sum %>% 
  select(term, estimate, std.error, p.value)) %>%
  head(13)
print(imp_2_rp_sum_table)

```

## Regression 3

```{r results_printing_rp_impute_regressions_3, echo=FALSE}

# print results of 3rd regression

imp_3_rp_sum_table <- as.data.frame(imp_3_rp_sum %>% 
  select(term, estimate, std.error, p.value)) %>%
  head(13)
print(imp_3_rp_sum_table)
```

# Extension Part 2: Fin Seg Data Set

In the second, and arguably most important dataset in the analysis, the data set on financial segregation, there are a very large number of missing values. For example, on the main independent variable of interest, there are a whopping 282,334 missing values, or %`r round(282334/324178*100,2)` of the data. 

```{r include = FALSE}

# apply the conditions in Stata regression

fin_imp <- fin_seg %>%
  filter(totaltractsf > 1 | is.na(totaltractsf), dgepercap_cpi != 0) %>%
  mutate(medinc_cpi = medinc_cpi/1000)

# select the relevant variables

fin_imp <- fin_imp %>%
  select(H_citytract_NHW_i, dgepercap_cpi, diversityinterp, pctblkpopinterp, pctasianpopinterp,
         pctlatinopopinterp, medinc_cpi, pctlocalgovworker_100, pctrentersinterp, pctover65,
         pctcollegegradinterp, logpop, geo_id2, chng5pctblk, chng5pctlatino, chng5pctasian,
         ideology_fill)


miss_var_summary(fin_imp)

gg_miss_var(fin_imp, show_pct = TRUE)

gg_miss_var(fin_imp)

```
```{r echo = FALSE}

gg_miss_var(fin_imp, show_pct = TRUE)

```

```{r echo = FALSE}

# select all variables with missing values for the aggr plot

fin_imp_aggr <- fin_imp %>%
  select(H_citytract_NHW_i, diversityinterp, pctblkpopinterp, pctasianpopinterp,
         pctlatinopopinterp, medinc_cpi, pctlocalgovworker_100, pctrentersinterp, pctover65,
         pctcollegegradinterp, chng5pctblk, chng5pctlatino, chng5pctasian,
         ideology_fill)

aggr_plot <- aggr(fin_imp_aggr, bars = TRUE, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, cex.axis=.5, gap=3, ylab=c("Histogram of missing data","Pattern"))


# this plot tells us that only .066% of the data are complete (not missing anything)

nrow(fin_imp) * .0058
```

```{r include = FALSE}

# perform multiple imputations. We have the same issue here with the default method as with the previous dataset so we use CART. Additionally, because of the extremely large size of this dataset, we choose to only impute the variable H_citytract_NHW_i, as it is the most frequently missing variable and also out main independent variable. Just imputing this allows us to include way more observations in the regression than the original data despite the still large number of NAs overall. One concern here would be that if there was some reason that this variable was missing rather than other variables that only imputing this variable could lead to some bias in the results.  

# generate a blank run to get the method matrix

ini <- mice(fin_imp, maxit=0, print=F)

# view the current method settings

meth <- ini$method

# change the method variables for all variables except H_citytract_NHW_i to ""
# so that their missing values aren't imputed

meth[c("dgepercap_cpi", "diversityinterp", "pctblkpopinterp", "pctasianpopinterp",
         "pctlatinopopinterp", "medinc_cpi", "pctlocalgovworker_100", "pctrentersinterp",
         "pctover65", "pctcollegegradinterp", "logpop", "geo_id2")]=""

# other

other <- c("chng5pctblk", 
       "chng5pctlatino", "chng5pctasian", "ideology_fill")

# change the default method to "cart" so that we don't get the error

meth[c("H_citytract_NHW_i", "chng5pctblk", 
       "chng5pctlatino", "chng5pctasian", "ideology_fill")] = "cart"

imp_2_fs <- mice(fin_imp, method = meth, maxit = 5)

# now there are manyb fewer missing variables!!!

# miss_var_summary(complete(imp_2_fs))


```


Finding no clear patterns in the missing data, I next performed mutliple imputations (with 5 iterations) on the dataset. A non-stochastic imputation method, Classification and Regression Trees (CART), was used instead of the default because of an error with matrix inversion caused by the data. Before examining the results of Trounstine's model using the imputed data, I first run some diagnostic tests of the imputation results to make sure that everything is running as expected. 

First, I check the convergence of the algorithm used within mice() for each of the variables. For the most part, the fits intertwine and do not exhibit any trends at later iterations, as desired. 

```{r fs_imp_plot, echo = FALSE}

# ideally, the fits will intertwine and not exhibit any trends at later iterations. This seems to generally be the case. There are some issues with the results for some of the variables with very few missing values, which makes sense as we would expect the mean to be less reliable due to the law of large numbers and thus convergence is more difficult. However, since these are so few values, it is less important about how robust they are. 

plot(imp_2_fs)

```

We can also check the imputed values against the original values using stripplot(). Each column in each subplot represents a separate iteration. The magenta points represent the imputed data. The values of the variable in questions are along the y axis. We expect the spread of the data to be similar if the imputations were done well. If the data were missing completely at random, then the imputed data should have the same distribution as the original data. In particular, we want to be sure that the imputations are within a plausible range of the data. This is the case for all of our imputed variables, and there does not seem to be cause for alarm from these results. 

```{r fs_stripplot, echo = FALSE}

# we can also check the imputed values against the original values using stripplot(). Each column in each subplot represents a separate iteration. The magenta points represent the imputed data. The values of the variable in questions are along the y axis. We expect the spread of the data to be similar if the imputations were done well. If the data were missing completely at random, then the imputed data should have the same distribution as the original data. In particular, we want to be sure that the imputations are within a plausible range of the data. This is the case for all of our imputed variables, and there does not seem to be cause for alarm from these results. 

# this looks good? All reasonable values...

stripplot(imp_2_fs, H_citytract_NHW_i)

stripplot(imp_2_fs, chng5pctblk)

stripplot(imp_2_fs, chng5pctlatino)

stripplot(imp_2_fs, ideology_fill)

```

Finally, we can also look at the density plots for each variable's actual data and for their imputed data from each of the iterations, which are represented in magenta. Overall, the density plots align quite well for the variables.

```{r fs_densityplot, echo = FALSE}

densityplot(imp_2_fs)
densityplot( x=imp_2_fs , data= ~ H_citytract_NHW_i + chng5pctblk + 
       chng5pctlatino + chng5pctasian + ideology_fill)
```

While the imputations are not perfect, there do not seem to be any major problems so far. Thus, we can now proceed with our analysis. We fit each of our 5 imputed datasets to Trounstine's 3 models using this data and then pool the results for each. The results are as follows:


```{r include = FALSE}
# Main Analysis 2: Imputations


## regression 1 Table 2

# fit multiple imputed datasets

fit_imp_felm1 <- with(imp_2_fs, felm(dgepercap_cpi ~ H_citytract_NHW_i + diversityinterp + pctblkpopinterp + pctasianpopinterp + pctlatinopopinterp + medinc_cpi + pctlocalgovworker_100 + pctrentersinterp + pctover65 + pctcollegegradinterp + logpop | factor(geo_id2) |0| geo_id2))

# pool the analyses

pool_imp_felm1 <- pool(fit_imp_felm1)
imp_felm1_sum <- summary(pool_imp_felm1)


## regression 2 Table 2

# fit multiple imputed datasets

fit_imp_felm2 <- with(imp_2_fs, felm(dgepercap_cpi ~ H_citytract_NHW_i + pctblkpopinterp + pctasianpopinterp + pctlatinopopinterp + chng5pctblk + chng5pctlatino + chng5pctasian+ medinc_cpi + pctlocalgovworker_100 + pctrentersinterp + pctover65 + pctcollegegradinterp + logpop | factor(geo_id2) |0| geo_id2))

# pool the analyses

pool_imp_felm2 <- pool(fit_imp_felm2)
imp_felm2_sum <- summary(pool_imp_felm2)



## Regression 3 Table 2

fit_imp_felm3 <- with(imp_2_fs, felm(dgepercap_cpi ~ H_citytract_NHW_i + diversityinterp + pctblkpopinterp + pctasianpopinterp + pctlatinopopinterp + medinc_cpi + pctlocalgovworker_100 + pctrentersinterp + pctover65 + pctcollegegradinterp + logpop + ideology_fill | factor(geo_id2) |0| geo_id2))

# pool the analyses

pool_imp_felm3 <- pool(fit_imp_felm3)
imp_felm3_sum <- summary(pool_imp_felm3)

```

## Regression 1

The results of the first regression indicate that Trounstine's results are robust to the inclusion of the imputed data, which led to the inclusion of an additional 59,377 observaitons in the analysis. The coefficients, standard errors, and significance levels are essentially unchanged. The same is largely true for the second and third specifications, but the magnitude of the coefficient on the segregation decreases by a marginal amount. 

```{r results_printing_fs_impute_regressions_1, echo=FALSE}

# print results of 3rd regression

imp_felm1_sum_table <- as.data.frame(imp_felm1_sum %>% 
  select(term, estimate, std.error, p.value))
print(imp_felm1_sum_table)
```

```{r results_printing_fs_impute_regressions_2, echo=FALSE}

# print results of 3rd regression

imp_felm2_sum_table <- as.data.frame(imp_felm2_sum %>% 
  select(term, estimate, std.error, p.value))
print(imp_felm2_sum_table)
```

```{r results_printing_fs_impute_regressions_3, echo=FALSE}

# print results of 3rd regression

imp_felm3_sum_table <- as.data.frame(imp_felm3_sum %>% 
  select(term, estimate, std.error, p.value))
print(imp_felm3_sum_table)
```

```{r include = FALSE}
# how many observations were included in those 3 analyses?

# basic filter for table for all regressions

# xtreg dgepercap_cpi H_citytract_NHW_i diversityinterp pctblkpopinterp
# pctasianpopinterp pctlatinopopinterp medinc_cpi pctlocalgovworker_100
# pctrentersinterp pctover65 pctcollegegradinterp logpop if totaltracts>1 &
# dgepercap_cpi~=0,fe vce(cluster geo_id2)

sum(is.na(complete(imp_2_fs)$H_citytract_NHW_i))
sum(is.na(complete(imp_2_fs,1)$H_citytract_NHW_i))
sum(is.na(complete(imp_2_fs,2)$H_citytract_NHW_i))
sum(is.na(complete(imp_2_fs,3)$H_citytract_NHW_i))
sum(is.na(complete(imp_2_fs,4)$H_citytract_NHW_i))
sum(is.na(complete(imp_2_fs,5)$H_citytract_NHW_i))

fin <- complete(imp_2_fs) %>%
  filter(!(is.na(dgepercap_cpi)), !(is.na(H_citytract_NHW_i)), !(is.na(diversityinterp)),
         !(is.na(pctblkpopinterp)), !(is.na(pctasianpopinterp)), !(is.na(pctlatinopopinterp)),
         !(is.na(medinc_cpi)), !(is.na(pctlocalgovworker_100)), !(is.na(pctrentersinterp)),
         !(is.na(pctover65)), !(is.na(pctcollegegradinterp)), !(is.na(logpop)))

# create dge variable used in regression

fin_dge <-fin %>% filter(dgepercap_cpi != 0)

fin_dge_tab <- tibble(
  Variable = "Direct General Expenditure per Capita",
  Obs = nrow(fin_dge),
  Mean = mean(fin_dge$dgepercap_cpi, na.rm = T),
  SD = sd(fin_dge$dgepercap_cpi, na.rm = T),
  Min = min(fin_dge$dgepercap_cpi, na.rm = T),
  Max = max(fin_dge$dgepercap_cpi, na.rm = T)
)

print(fin_dge_tab)

# now we have 73,119 observations compared to 13,742

nrow(fin_seg)

# number of missing seg indexes before imputation: 282334

# number missing now: 222957
282334 - 222957

73119-13742

# we were able to increase sample size by 59,377

miss_var_summary(complete(imp_2_fs))

```

